{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(13), Dimension(5), Dimension(200)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math_funcs import squash, safe_norm\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_builder import build_rand_feat, get_training_data_conv\n",
    "from cfg import AudioConfig\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from modfilescapcnn import *\n",
    "\n",
    "# # Primary Capsules\n",
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * 13 * 5  # 1152 primary capsules\n",
    "caps1_n_dims = 8\n",
    "\n",
    "caps2_n_caps = 8\n",
    "caps2_n_dims = 16\n",
    "\n",
    "X, y, mask_with_labels = model_inputs()\n",
    "conv2 = build_cnn_layers(X, caps1_n_maps, caps1_n_dims)\n",
    "conv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_output_round_2 = build_capsnet_layers(conv2, caps1_n_caps, caps1_n_dims, X)\n",
    "caps2_output = caps2_output_round_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = get_y_pred(caps2_output)\n",
    "\n",
    "margin_loss = get_margin_loss(y, caps2_output, caps2_n_caps)\n",
    "\n",
    "# # Reconstruction\n",
    "# ## Mask\n",
    "\n",
    "decoder_input = get_decoder_input(mask_with_labels, y, y_pred, caps2_output, caps2_n_caps, caps2_n_dims)\n",
    "\n",
    "n_output = 39 * 13\n",
    "decoder_output = get_decoder_output(decoder_input, n_output)\n",
    "\n",
    "# ## Reconstruction Loss\n",
    "reconstruction_loss = get_reconstruction_loss(X, n_output, decoder_output)\n",
    "\n",
    "# ## Final Loss\n",
    "alpha = 0.0005\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "# # Final Touches\n",
    "# ## Accuracy\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "# ## Training Operations\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "# ## Init and Saver\n",
    "# And let's add the usual variable initializer, as well as a `Saver`:\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# # Training\n",
    "X_, y_ = get_training_data_conv()\n",
    "\n",
    "n_epochs = 1  # 20\n",
    "batch_size = 50\n",
    "restore_checkpoint = False  # True\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2)  # , random_state = 0)\n",
    "\n",
    "n_iterations_per_epoch = len(X_train) // batch_size\n",
    "n_iterations_validation = len(X_test) // batch_size\n",
    "\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network_emotion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = X_train[(iteration - 1) * batch_size: iteration * batch_size]\n",
    "            y_batch = y_train[(iteration - 1) * batch_size: iteration * batch_size]\n",
    "            # Run the training operation and measure the loss:\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={  # X: X_batch.reshape([-1, 28, 28, 1]), #need to fix these shapes\n",
    "                    X: X_batch,  # need to fix these shapes\n",
    "                    y: np.argmax(y_batch, axis=1),  # one-hot to index,\n",
    "                    mask_with_labels: True\n",
    "                })\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                iteration, n_iterations_per_epoch,\n",
    "                iteration * 100 / n_iterations_per_epoch,\n",
    "                loss_train),\n",
    "                end=\"\")\n",
    "\n",
    "        # At the end of each epoch,\n",
    "        # measure the validation loss and accuracy:\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = X_test[(iteration - 1) * batch_size: iteration * batch_size]\n",
    "            y_batch = y_test[(iteration - 1) * batch_size: iteration * batch_size]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                [loss, accuracy],\n",
    "                feed_dict={  # X: X_batch.reshape([-1, 28, 28, 1]), #need to fix these shapes\n",
    "                    X: X_batch,  # need to fix these shapes\n",
    "                    # y: y_batch\n",
    "                    y: np.argmax(y_batch, axis=1)  # one-hot to index\n",
    "                })\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                iteration, n_iterations_validation,\n",
    "                iteration * 100 / n_iterations_validation),\n",
    "                end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "n_iterations_test = len(X_test) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for iteration in range(1, n_iterations_test + 1):\n",
    "        # X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        X_batch = X_test[(iteration - 1) * batch_size: iteration * batch_size]\n",
    "        y_batch = y_test[(iteration - 1) * batch_size: iteration * batch_size]\n",
    "        loss_test, acc_test = sess.run(\n",
    "            [loss, accuracy],\n",
    "            feed_dict={  # X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                # y: y_batch\n",
    "                X: X_batch,  # need to fix these shapes\n",
    "                y: np.argmax(y_batch, axis=1)  # one-hot to index\n",
    "            })\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "            iteration, n_iterations_test,\n",
    "            iteration * 100 / n_iterations_test),\n",
    "            end=\" \" * 10)\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
    "        acc_test * 100, loss_test))\n",
    "\n",
    "    assert acc_test * 100 > 23, acc_test * 100\n",
    "\n",
    "# # Predictions\n",
    "#capsCNNemotionModularPrediction.py\n",
    "\n",
    "# Note: we feed `y` with an empty array, but TensorFlow will not use it, as explained earlier.\n",
    "# Plot the images and their labels, followed by the corresponding reconstructions and predictions:\n",
    "#capsCNNemotionModularPrediction.py\n",
    "\n",
    "# Tweak output vectors to see what their pose parameters represent\n",
    "#capsCNNemotionModularPrediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
